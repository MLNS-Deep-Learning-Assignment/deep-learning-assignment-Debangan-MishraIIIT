{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from models import CNNRegressor, CNNClassifier, VGGRegressor\n",
    "from dataloader import get_loaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_model(model_type, seed):\n",
    "    if model_type == \"CNNRegressor\":\n",
    "        model = CNNRegressor()\n",
    "        model_name = f\"trained_models/cnnregressor_{seed}.pt\"\n",
    "    elif model_type == \"CNNClassifier\":\n",
    "        model = CNNClassifier()\n",
    "        model_name = f\"trained_models/cnnlassifier_{seed}.pt\"\n",
    "    elif model_type == \"VGGRegressor\":\n",
    "        model = VGGRegressor()\n",
    "        model_name = f\"trained_models/vggregressor_{seed}.pt\"\n",
    "    model.load_state_dict(torch.load(model_name))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_fraction = 0.8\n",
    "batch_size = 62\n",
    "seed = 42\n",
    "train_loader, val_loader = get_loaders(train_fraction, batch_size, seed)\n",
    "model_type = \"CNNRegressor\"\n",
    "model = get_model(model_type, seed).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of Regressor on Validation Split: 10.65%\n",
      "Overall Accuracy of Regressor on Training Split: 18.16%\n"
     ]
    }
   ],
   "source": [
    "if model_type == \"CNNRegressor\" or \"VGGRegressor\":\n",
    "    ## Calculating overall accuracy of the validation set\n",
    "    model.eval()\n",
    "    total_len = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            correct_count = (torch.sum(torch.round(outputs)==y)).item()\n",
    "            total_len += len(y)\n",
    "            total_correct += correct_count\n",
    "    accuracy = (total_correct/total_len)*100\n",
    "    print(f\"Overall Accuracy of Regressor on Validation Split: {accuracy:.2f}%\")\n",
    "\n",
    "    total_len = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            correct_count = (torch.sum(torch.round(outputs)==y)).item()\n",
    "            total_len += len(y)\n",
    "            total_correct += correct_count\n",
    "    accuracy = (total_correct/total_len)*100\n",
    "    print(f\"Overall Accuracy of Regressor on Training Split: {accuracy:.2f}%\")\n",
    "else:\n",
    "    model.eval()\n",
    "    total_len = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in val_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            outputs = F.softmax(outputs, dim=-1)\n",
    "            outputs = torch.argmax(outputs, dim=1)\n",
    "            correct_count = (torch.sum(torch.round(outputs)==y)).item()\n",
    "            total_len += len(y)\n",
    "            total_correct += correct_count\n",
    "    accuracy = (total_correct/total_len)*100\n",
    "    print(f\"Overall Accuracy of Classifer on Validation Split: {accuracy:.2f}%\")\n",
    "\n",
    "    total_len = 0\n",
    "    total_correct = 0\n",
    "    with torch.no_grad():\n",
    "        for x, y in train_loader:\n",
    "            x, y = x.to(device), y.to(device)\n",
    "            outputs = model(x)\n",
    "            outputs = F.softmax(outputs, dim=-1)\n",
    "            outputs = torch.argmax(outputs, dim=1)\n",
    "            correct_count = (torch.sum(torch.round(outputs)==y)).item()\n",
    "            total_len += len(y)\n",
    "            total_correct += correct_count\n",
    "    accuracy = (total_correct/total_len)*100\n",
    "    print(f\"Overall Accuracy of Classifer on Training Split: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above part is just a copy of the relevant sections in the training code. Given the allround good performance of the CNN Regressor (seed 42) across both training and validation splits (without overfitting), that will be the final model I wish to submit for evaluation. In the subsequent code, I will train the model for a final time on the whole dataset (without train or test splitting) to ensure that the model is able to train over the complete data provided. The code can be commented if the final_model.pt file (representing the state dictionary of the model) is already present. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataloader import get_loaders\n",
    "from torch import nn\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import torch\n",
    "from models import CNNRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "seed = 42\n",
    "epochs = 15\n",
    "learning_rate = 1e-3\n",
    "batch_size = 64\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "train_loader = get_loaders(1, batch_size, seed, full_data_return= True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)\n",
    "torch.cuda.manual_seed(seed)\n",
    "torch.cuda.manual_seed_all(seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_model = CNNRegressor().to(device)\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(final_model.parameters(), lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/15, Train Loss: 32.7529, Average Train Accuracy: 6.6831\n",
      "Epoch 2/15, Train Loss: 19.3948, Average Train Accuracy: 9.0307\n",
      "Epoch 3/15, Train Loss: 14.0098, Average Train Accuracy: 10.6610\n",
      "Epoch 4/15, Train Loss: 11.4056, Average Train Accuracy: 11.8925\n",
      "Epoch 5/15, Train Loss: 9.8578, Average Train Accuracy: 13.0486\n",
      "Epoch 6/15, Train Loss: 8.8819, Average Train Accuracy: 13.2507\n",
      "Epoch 7/15, Train Loss: 8.2647, Average Train Accuracy: 14.3657\n",
      "Epoch 8/15, Train Loss: 7.6257, Average Train Accuracy: 14.8943\n",
      "Epoch 9/15, Train Loss: 7.3247, Average Train Accuracy: 14.8832\n",
      "Epoch 10/15, Train Loss: 6.6234, Average Train Accuracy: 15.5983\n",
      "Epoch 11/15, Train Loss: 6.0760, Average Train Accuracy: 16.6167\n",
      "Epoch 12/15, Train Loss: 6.1472, Average Train Accuracy: 16.1270\n",
      "Epoch 13/15, Train Loss: 4.8328, Average Train Accuracy: 18.0404\n",
      "Epoch 14/15, Train Loss: 3.9300, Average Train Accuracy: 20.5413\n",
      "Epoch 15/15, Train Loss: 4.0415, Average Train Accuracy: 20.1759\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    final_model.train()\n",
    "    train_loss = 0.0\n",
    "    train_acc = 0.0\n",
    "\n",
    "    for images, labels in train_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = final_model(images)\n",
    "        loss = criterion(outputs.squeeze(), labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        train_loss += loss.item()\n",
    "\n",
    "        accuracy = (torch.sum(torch.round(outputs)==labels)*100/len(labels)).item()\n",
    "        train_acc += accuracy\n",
    "\n",
    "    print(f\"Epoch {epoch+1}/{epochs}, Train Loss: {train_loss/len(train_loader):.4f}, Average Train Accuracy: {train_acc/len(train_loader):.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(final_model.state_dict(), f\"./final_model.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall Accuracy of Regressor on Training Split: 21.49%\n"
     ]
    }
   ],
   "source": [
    "total_len = 0\n",
    "total_correct = 0\n",
    "with torch.no_grad():\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.to(device), y.to(device)\n",
    "        outputs = final_model(x)\n",
    "        correct_count = (torch.sum(torch.round(outputs)==y)).item()\n",
    "        total_len += len(y)\n",
    "        total_correct += correct_count\n",
    "accuracy = (total_correct/total_len)*100\n",
    "print(f\"Overall Accuracy of Regressor on Training Split: {accuracy:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As reported earlier in the training code, as well as the report, the validation accuracy of the current model is 10.65% but in different runs, it reaches up to 12-14% (owing to the stochastic nature of training models on GPU devices). The train accuracy reaches 20%. When no validation split is performed, the training accuracy on the full data reaches 21.49%. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
